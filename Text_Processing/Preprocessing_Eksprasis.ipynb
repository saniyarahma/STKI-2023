{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5542d305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ekphrasis in c:\\users\\user\\anaconda3\\lib\\site-packages (0.5.4)\n",
      "Requirement already satisfied: ujson in c:\\users\\user\\anaconda3\\lib\\site-packages (from ekphrasis) (5.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\lib\\site-packages (from ekphrasis) (3.7.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\user\\anaconda3\\lib\\site-packages (from ekphrasis) (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from ekphrasis) (4.64.1)\n",
      "Requirement already satisfied: termcolor in c:\\users\\user\\anaconda3\\lib\\site-packages (from ekphrasis) (2.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from ekphrasis) (0.4.6)\n",
      "Requirement already satisfied: ftfy in c:\\users\\user\\anaconda3\\lib\\site-packages (from ekphrasis) (6.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from ekphrasis) (1.24.3)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ftfy->ekphrasis) (0.2.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->ekphrasis) (9.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->ekphrasis) (22.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->ekphrasis) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->ekphrasis) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->ekphrasis) (1.0.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->ekphrasis) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->ekphrasis) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->ekphrasis) (2.8.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk->ekphrasis) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk->ekphrasis) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk->ekphrasis) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->ekphrasis) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ekphrasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47060ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\ekphrasis\\classes\\tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
      "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\ekphrasis\\classes\\exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
      "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n"
     ]
    }
   ],
   "source": [
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "\n",
    "text_processor = TextPreProcessor(\n",
    "    # terms that will be normalized\n",
    "    normalize=['email', 'percent', 'money', 'phone', 'user',\n",
    "        'time', 'date', 'number'],\n",
    "    # terms that will be annotated\n",
    "    #annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",'emphasis', 'censored'},\n",
    "    annotate={\"hashtag\",\"allcaps\",\"elongated\",\"repeated\",'emphasis','censored'},\n",
    "    fix_html=True,  # fix HTML tokens\n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for word segmentation \n",
    "    segmenter=\"twitter\", \n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for spell correction\n",
    "    corrector=\"twitter\", \n",
    "    \n",
    "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
    "    spell_correct_elong=False,  # spell correction for elongated words\n",
    "    \n",
    "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
    "    # the tokenizer, should take as input a string and return a list of tokens\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "    \n",
    "    # list of dictionaries, for replacing tokens extracted from the text,\n",
    "    # with other expressions. You can pass more than one dictionaries.\n",
    "    dicts=[emoticons]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8a07663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bersih_eks(kata):\n",
    "  return \" \".join(text_processor.pre_process_doc(kata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ba92e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "kalimat = \"@kiyokakudo wah keren banget anime one piece, gasabar liat live actionyya mantap yeyeye>:) #anime #wibuu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd33f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil01 = bersih_eks(kalimat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5e8eef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<user> wah keren banget anime one piece , gasabar liat live actionyya mantap yeyeye <devil> <hashtag> anime </hashtag> <hashtag> wi buu </hashtag>\n"
     ]
    }
   ],
   "source": [
    "print(hasil01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5db6ce42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiibuu <elongated>\n"
     ]
    }
   ],
   "source": [
    "kalimat2 = 'wiiiiiiiiiiiiiiibuuuuuuuuuuuu'\n",
    "hasil02 = bersih_eks(kalimat2)\n",
    "print(hasil02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000533d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
