{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24699188",
   "metadata": {},
   "source": [
    "# Document Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a29bc7",
   "metadata": {},
   "source": [
    "# Rekomendasi Buku dengan Kemiripan Dokumen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7df0a0",
   "metadata": {},
   "source": [
    "Rekomendasi buku adalah aplikasi yang serupa dengan rekomendasi film, tetapi dalam konteks rekomendasi buku, kita ingin merekomendasikan buku kepada pembaca berdasarkan minat mereka. Berikut adalah tiga pendekatan yang serupa dengan rekomendasi buku:\n",
    "\n",
    "Simple Rule-based Recommenders :\n",
    "- Rekomendasi berdasarkan popularitas buku: Menampilkan buku-buku populer yang banyak dibaca atau dinilai tinggi oleh pembaca lain.\n",
    "- Rekomendasi berdasarkan genre: Memberikan buku-buku dalam genre yang sesuai dengan minat pembaca. Misalnya, jika seseorang suka fiksi ilmiah, rekomendasikan buku-buku dalam genre tersebut.\n",
    "\n",
    "Content-based Recommenders:\n",
    "- Rekomendasi berdasarkan atribut buku: Menganalisis atribut konten buku seperti deskripsi, genre, penulis, dan kata kunci. Selain itu, dapat merekomendasikan buku dengan atribut yang serupa dengan buku yang telah disukai oleh pembaca.\n",
    "- Analisis sentimen ulasan buku: Menganalisis sentimen ulasan pembaca untuk buku-buku dan merekomendasikan buku dengan sentimen positif yang mirip dengan buku yang disukai.\n",
    "\n",
    "Collaborative Filtering Recommenders:\n",
    "- Menganalisis preferensi pembaca: Menganalisis preferensi pembaca berdasarkan buku yang telah mereka baca atau dinilai. Jika dua pembaca memiliki preferensi yang serupa, kita dapat merekomendasikan buku yang satu telah membaca kepada yang lain.\n",
    "- Filtering berbasis peringkat: Menggunakan peringkat yang diberikan oleh pembaca untuk buku-buku tertentu. Jika dua pembaca memberikan peringkat yang mirip untuk buku yang sama, sistem dapat merekomendasikan buku tersebut kepada keduanya.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f2ea6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textsearch in c:\\users\\user\\anaconda3\\lib\\site-packages (0.0.24)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\user\\anaconda3\\lib\\site-packages (from textsearch) (2.0.0)\n",
      "Requirement already satisfied: anyascii in c:\\users\\user\\anaconda3\\lib\\site-packages (from textsearch) (0.3.2)\n",
      "Requirement already satisfied: contractions in c:\\users\\user\\anaconda3\\lib\\site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\user\\anaconda3\\lib\\site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\user\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n",
      "Requirement already satisfied: anyascii in c:\\users\\user\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install textsearch\n",
    "!pip install contractions\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f2871db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/User')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "pathlib.Path().resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcd9dc6",
   "metadata": {},
   "source": [
    "# load dan view data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9031739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Unnamed: 0   10000 non-null  int64  \n",
      " 1   Book         10000 non-null  object \n",
      " 2   Author       10000 non-null  object \n",
      " 3   Description  9923 non-null   object \n",
      " 4   Genres       10000 non-null  object \n",
      " 5   Avg_Rating   10000 non-null  float64\n",
      " 6   Num_Ratings  10000 non-null  object \n",
      " 7   URL          10000 non-null  object \n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 625.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Book</th>\n",
       "      <th>Author</th>\n",
       "      <th>Description</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Avg_Rating</th>\n",
       "      <th>Num_Ratings</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>['Classics', 'Fiction', 'Historical Fiction', ...</td>\n",
       "      <td>4.27</td>\n",
       "      <td>5,691,311</td>\n",
       "      <td>https://www.goodreads.com/book/show/2657.To_Ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Harry Potter and the Philosopher’s Stone (Harr...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>Harry Potter thinks he is an ordinary boy - un...</td>\n",
       "      <td>['Fantasy', 'Fiction', 'Young Adult', 'Magic',...</td>\n",
       "      <td>4.47</td>\n",
       "      <td>9,278,135</td>\n",
       "      <td>https://www.goodreads.com/book/show/72193.Harr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>Since its immediate success in 1813, Pride and...</td>\n",
       "      <td>['Classics', 'Fiction', 'Romance', 'Historical...</td>\n",
       "      <td>4.28</td>\n",
       "      <td>3,944,155</td>\n",
       "      <td>https://www.goodreads.com/book/show/1885.Pride...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Diary of a Young Girl</td>\n",
       "      <td>Anne Frank</td>\n",
       "      <td>Discovered in the attic in which she spent the...</td>\n",
       "      <td>['Classics', 'Nonfiction', 'History', 'Biograp...</td>\n",
       "      <td>4.18</td>\n",
       "      <td>3,488,438</td>\n",
       "      <td>https://www.goodreads.com/book/show/48855.The_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>Librarian's note: There is an Alternate Cover ...</td>\n",
       "      <td>['Classics', 'Fiction', 'Dystopia', 'Fantasy',...</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3,575,172</td>\n",
       "      <td>https://www.goodreads.com/book/show/170448.Ani...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Book  \\\n",
       "0           0                              To Kill a Mockingbird   \n",
       "1           1  Harry Potter and the Philosopher’s Stone (Harr...   \n",
       "2           2                                Pride and Prejudice   \n",
       "3           3                          The Diary of a Young Girl   \n",
       "4           4                                        Animal Farm   \n",
       "\n",
       "          Author                                        Description  \\\n",
       "0     Harper Lee  The unforgettable novel of a childhood in a sl...   \n",
       "1   J.K. Rowling  Harry Potter thinks he is an ordinary boy - un...   \n",
       "2    Jane Austen  Since its immediate success in 1813, Pride and...   \n",
       "3     Anne Frank  Discovered in the attic in which she spent the...   \n",
       "4  George Orwell  Librarian's note: There is an Alternate Cover ...   \n",
       "\n",
       "                                              Genres  Avg_Rating Num_Ratings  \\\n",
       "0  ['Classics', 'Fiction', 'Historical Fiction', ...        4.27   5,691,311   \n",
       "1  ['Fantasy', 'Fiction', 'Young Adult', 'Magic',...        4.47   9,278,135   \n",
       "2  ['Classics', 'Fiction', 'Romance', 'Historical...        4.28   3,944,155   \n",
       "3  ['Classics', 'Nonfiction', 'History', 'Biograp...        4.18   3,488,438   \n",
       "4  ['Classics', 'Fiction', 'Dystopia', 'Fantasy',...        3.98   3,575,172   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://www.goodreads.com/book/show/2657.To_Ki...  \n",
       "1  https://www.goodreads.com/book/show/72193.Harr...  \n",
       "2  https://www.goodreads.com/book/show/1885.Pride...  \n",
       "3  https://www.goodreads.com/book/show/48855.The_...  \n",
       "4  https://www.goodreads.com/book/show/170448.Ani...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"goodreads_data.csv\")\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db504f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 1468 to 3747\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Book         10000 non-null  object\n",
      " 1   Author       10000 non-null  object\n",
      " 2   Genres       10000 non-null  object\n",
      " 3   Num_Ratings  10000 non-null  object\n",
      " 4   description  10000 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 468.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df[['Book', 'Author', 'Genres', 'Num_Ratings']]\n",
    "df.Author.fillna('', inplace=True)\n",
    "df['description'] = df['Author'].map(str) + ' ' + df['Genres']\n",
    "df.dropna(inplace=True)\n",
    "df = df.sort_values(by=['Num_Ratings'], ascending=False)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b81e3ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book</th>\n",
       "      <th>Author</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Num_Ratings</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>Hometown Girl After All (Hometown, #2)</td>\n",
       "      <td>Kirsten Fullmer</td>\n",
       "      <td>['Contemporary', 'Young Adult', 'New Adult', '...</td>\n",
       "      <td>999</td>\n",
       "      <td>Kirsten Fullmer ['Contemporary', 'Young Adult'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033</th>\n",
       "      <td>Hometown Girl After All (Hometown, #2)</td>\n",
       "      <td>Kirsten Fullmer</td>\n",
       "      <td>['Contemporary', 'Young Adult', 'New Adult', '...</td>\n",
       "      <td>999</td>\n",
       "      <td>Kirsten Fullmer ['Contemporary', 'Young Adult'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4735</th>\n",
       "      <td>Belonging (Temptation, #2)</td>\n",
       "      <td>Karen Ann Hopkins</td>\n",
       "      <td>['Young Adult', 'Romance', 'Amish', 'Contempor...</td>\n",
       "      <td>998</td>\n",
       "      <td>Karen Ann Hopkins ['Young Adult', 'Romance', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7411</th>\n",
       "      <td>تشي</td>\n",
       "      <td>أحمد خالد توفيق</td>\n",
       "      <td>['Fiction', 'Novels', 'Fantasy']</td>\n",
       "      <td>998</td>\n",
       "      <td>أحمد خالد توفيق ['Fiction', 'Novels', 'Fantasy']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>Living The Best Day Ever</td>\n",
       "      <td>Hendri Coetzee</td>\n",
       "      <td>['Nonfiction', 'Adventure']</td>\n",
       "      <td>997</td>\n",
       "      <td>Hendri Coetzee ['Nonfiction', 'Adventure']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Book             Author  \\\n",
       "1468  Hometown Girl After All (Hometown, #2)    Kirsten Fullmer   \n",
       "3033  Hometown Girl After All (Hometown, #2)    Kirsten Fullmer   \n",
       "4735              Belonging (Temptation, #2)  Karen Ann Hopkins   \n",
       "7411                                     تشي    أحمد خالد توفيق   \n",
       "2796                Living The Best Day Ever     Hendri Coetzee   \n",
       "\n",
       "                                                 Genres Num_Ratings  \\\n",
       "1468  ['Contemporary', 'Young Adult', 'New Adult', '...         999   \n",
       "3033  ['Contemporary', 'Young Adult', 'New Adult', '...         999   \n",
       "4735  ['Young Adult', 'Romance', 'Amish', 'Contempor...         998   \n",
       "7411                   ['Fiction', 'Novels', 'Fantasy']         998   \n",
       "2796                        ['Nonfiction', 'Adventure']         997   \n",
       "\n",
       "                                            description  \n",
       "1468  Kirsten Fullmer ['Contemporary', 'Young Adult'...  \n",
       "3033  Kirsten Fullmer ['Contemporary', 'Young Adult'...  \n",
       "4735  Karen Ann Hopkins ['Young Adult', 'Romance', '...  \n",
       "7411   أحمد خالد توفيق ['Fiction', 'Novels', 'Fantasy']  \n",
       "2796         Hendri Coetzee ['Nonfiction', 'Adventure']  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "343e319b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Georgette Heyer ['Romance', 'Historical Fiction', 'Historical Romance', 'Historical', 'Fiction', 'Regency', 'Classics']\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[4799].description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab5f39e",
   "metadata": {},
   "source": [
    "# Bangun Sistem Rekomendasi Film\n",
    "\n",
    "Tahapan\n",
    "- Pre Processing\n",
    "- Feature Engineering\n",
    "- Komputasi Doc Similarity\n",
    "- Proses Retrieve\n",
    "- proses rekomendasi film\n",
    "\n",
    "\n",
    "## Kemiripan Dokumen / document similarity\n",
    "\n",
    "Ada berbagai cara untuk menghitung kesamaan antara dua item dokumen. Salah satu ukuran yang paling banyak digunakan adalah __cosine similarity__ .\n",
    "\n",
    "### Cosine Similarity\n",
    "\n",
    "Cosine Similarity digunakan untuk menghitung skor numerik untuk menunjukkan kesamaan antara dua dokumen teks. Secara matematis, ini didefinisikan sebagai berikut:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2544bf80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import contractions\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    doc = contractions.fix(doc)\n",
    "    # tokenize document\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    #filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "\n",
    "norm_corpus = normalize_corpus(list(df['description']))\n",
    "len(norm_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997fc7c3",
   "metadata": {},
   "source": [
    "## Extrak TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "03e6a073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10023)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "tfidf_matrix = tf.fit_transform(norm_corpus)\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bed766f",
   "metadata": {},
   "source": [
    "## Compute Pairwise Document Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "677782f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9990</th>\n",
       "      <th>9991</th>\n",
       "      <th>9992</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9996</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.113022</td>\n",
       "      <td>0.008637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073988</td>\n",
       "      <td>0.007678</td>\n",
       "      <td>0.028422</td>\n",
       "      <td>0.055005</td>\n",
       "      <td>0.056849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.113022</td>\n",
       "      <td>0.008637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073988</td>\n",
       "      <td>0.007678</td>\n",
       "      <td>0.028422</td>\n",
       "      <td>0.055005</td>\n",
       "      <td>0.056849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.113022</td>\n",
       "      <td>0.113022</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079170</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>0.025027</td>\n",
       "      <td>0.048434</td>\n",
       "      <td>0.063815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008637</td>\n",
       "      <td>0.008637</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047804</td>\n",
       "      <td>0.066411</td>\n",
       "      <td>0.042331</td>\n",
       "      <td>0.157020</td>\n",
       "      <td>0.036816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.043812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3     4         5         6         7     \\\n",
       "0  1.000000  1.000000  0.113022  0.008637   0.0  0.073988  0.007678  0.028422   \n",
       "1  1.000000  1.000000  0.113022  0.008637   0.0  0.073988  0.007678  0.028422   \n",
       "2  0.113022  0.113022  1.000000  0.007605   0.0  0.079170  0.006760  0.025027   \n",
       "3  0.008637  0.008637  0.007605  1.000000   0.0  0.047804  0.066411  0.042331   \n",
       "4  0.000000  0.000000  0.000000  0.000000   1.0  0.043812  0.000000  0.000000   \n",
       "\n",
       "       8         9     ...  9990  9991  9992  9993  9994  9995  9996  9997  \\\n",
       "0  0.055005  0.056849  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1  0.055005  0.056849  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2  0.048434  0.063815  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "3  0.157020  0.036816  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "4  0.000000  0.042988  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   9998  9999  \n",
       "0   0.0   0.0  \n",
       "1   0.0   0.0  \n",
       "2   0.0   0.0  \n",
       "3   0.0   0.0  \n",
       "4   0.0   0.0  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "doc_sim = cosine_similarity(tfidf_matrix)\n",
    "doc_sim_df = pd.DataFrame(doc_sim)\n",
    "doc_sim_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379940b7",
   "metadata": {},
   "source": [
    "## mendapatkan judul buku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2240432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Hometown Girl After All (Hometown, #2)',\n",
       "        'Hometown Girl After All (Hometown, #2)',\n",
       "        'Belonging (Temptation, #2)', ..., 'witchbird',\n",
       "        'The Sense of a Deity',\n",
       "        'Broken: The Failed Promise of Muslim Inclusion'], dtype=object),\n",
       " (10000,))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_list = df['Book'].values\n",
    "book_list, book_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722156ea",
   "metadata": {},
   "source": [
    "# Temukan Film Serupa Teratas untuk Contoh Film\n",
    "Mari ambil Hometown Girl After All (Hometown, #2) buku yang memiliki ratung paling populer dari kerangka data di atas dan coba temukan buku paling mirip yang dapat direkomendasikan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c12d51c",
   "metadata": {},
   "source": [
    "## ambil book ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78c8ce9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_idx = np.where(book_list == 'Hometown Girl After All (Hometown, #2)')[0][0]\n",
    "book_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4b1ccd",
   "metadata": {},
   "source": [
    "## ambil similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f79b98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 0.11302219, ..., 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_similarities = doc_sim_df.iloc[book_idx].values\n",
    "book_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07c2b8f",
   "metadata": {},
   "source": [
    "## Get top 5 similar book IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1c0ca38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,   69, 9931, 9932, 3872], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_book_idxs = np.argsort(-book_similarities)[1:6]\n",
    "similar_book_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d82b5c",
   "metadata": {},
   "source": [
    "## Get top 5 similar books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8a6d0ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hometown Girl After All (Hometown, #2)',\n",
       "       'Christmas in Smithville (Hometown, #4)',\n",
       "       'Hometown Girl Forever (Hometown Series, #3)',\n",
       "       'Hometown Girl Forever (Hometown, #3)',\n",
       "       'Love on the Line (Women at Work, #1)'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_books = book_list[similar_book_idxs]\n",
    "similar_books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5782cd99",
   "metadata": {},
   "source": [
    "## Buat fungsi rekomendasi buku untuk merekomendasikan 5 buku serupa teratas untuk buku apa pun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e30e3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_recommender(book_title, books=book_list, doc_sims=doc_sim_df):\n",
    "    # find movie id\n",
    "    book_idx = np.where(books == book_title)[0][0]\n",
    "    # get movie similarities\n",
    "    book_similarities = doc_sims.iloc[book_idx].values\n",
    "    # get top 5 similar movie IDs\n",
    "    similar_book_idxs = np.argsort(-book_similarities)[1:6]\n",
    "    # get top 5 movies\n",
    "    similar_books = books[similar_book_idxs]\n",
    "    # return the top 5 movies\n",
    "    return similar_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7fd2ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_books = ['To Kill a Mockingbird', 'Pride and Prejudice', 'The Diary of a Young Girl', 'Animal Farm', \n",
    "                  'Hometown Girl After All (Hometown, #2)', 'Christmas in Smithville (Hometown, #4)', \n",
    "                  'Love on the Line (Women at Work, #1)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "90bb9ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books: To Kill a Mockingbird\n",
      "Top 5 recommended Books: ['Go Set a Watchman' 'A Separate Peace'\n",
      " 'The Adventures of Huckleberry Finn' 'The Scarlet Letter'\n",
      " 'The Fig Orchard']\n",
      "\n",
      "Books: Pride and Prejudice\n",
      "Top 5 recommended Books: ['Persuasion' 'Emma' 'Sense and Sensibility' 'The Complete Novels'\n",
      " 'Pride and Prejudice, Mansfield Park, Persuasion']\n",
      "\n",
      "Books: The Diary of a Young Girl\n",
      "Top 5 recommended Books: ['Rabbit-Proof Fence' 'The Auschwitz Chapter' 'The Complete Maus'\n",
      " 'Twelve Years a Slave' 'The Fields of Home (Little Britches, #5)']\n",
      "\n",
      "Books: Animal Farm\n",
      "Top 5 recommended Books: ['Animal Farm / 1984' '1984' 'Homage to Catalonia'\n",
      " 'The Road to Wigan Pier' 'Down and Out in Paris and London']\n",
      "\n",
      "Books: Hometown Girl After All (Hometown, #2)\n",
      "Top 5 recommended Books: ['Hometown Girl After All (Hometown, #2)'\n",
      " 'Christmas in Smithville (Hometown, #4)'\n",
      " 'Hometown Girl Forever (Hometown Series, #3)'\n",
      " 'Hometown Girl Forever (Hometown, #3)'\n",
      " 'Love on the Line (Women at Work, #1)']\n",
      "\n",
      "Books: Christmas in Smithville (Hometown, #4)\n",
      "Top 5 recommended Books: ['Hometown Girl After All (Hometown, #2)'\n",
      " 'Hometown Girl After All (Hometown, #2)'\n",
      " 'Hometown Girl Forever (Hometown Series, #3)'\n",
      " 'Hometown Girl Forever (Hometown, #3)'\n",
      " 'Love on the Line (Women at Work, #1)']\n",
      "\n",
      "Books: Love on the Line (Women at Work, #1)\n",
      "Top 5 recommended Books: ['Christmas in Smithville (Hometown, #4)'\n",
      " 'Hometown Girl at Heart (Hometown, #1)'\n",
      " 'Hometown Girl at Heart (Hometown, #1)'\n",
      " 'Hometown Girl Forever (Hometown Series, #3)'\n",
      " 'Hometown Girl Forever (Hometown, #3)']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for Book in popular_books:\n",
    "    print('Books:', Book )\n",
    "    print('Top 5 recommended Books:', book_recommender(book_title=Book, books=book_list, doc_sims=doc_sim_df))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
